{"cells":[{"source":"# 1. 交叉验证理论\n## 交叉验证\n对于模型的准确度，一般可以将预测结果和实际结果比对，从而轻松地得出。而模型地泛化误差（是不是过拟合）则相对较难度量。交叉验证是一种评估模型泛化误差地常见手段。\n## 具体步骤\n交叉验证法先将数据划分为k个大小相似的互斥子集。然后，每次选取k-1个子集进行训练，剩余的一个作为测试集。从而进行k次训练和测试，最终返回k次测试结果的均值。交叉验证的稳定性和保真性很大程度上取决于k的取值，k最常用的取值为10，这种交叉验证法又称“k折交叉验证”。\n## 留一法\n留一法是交叉验证的一种特殊情况，它将m个样本划分为m个子集，每次只取一个样本做测试集，其余全部为训练集。由于留一法每次只取出一个样本，每个训练模型都和需要评估的模型非常接近，因此被认为比较准确。但是在数据过多的情况下不建议使用。\n# 2. 交叉验证评估数据集\n## cross_value_score\n参数：(算法,数据集, 结果, cv, scoring)\n* cv取整数k时，按k折交叉验证方法分为k份\n* scoring:特殊的计算分数方法，默认none\n  * precision: 查准率\n  * recall: 查全率\n  * f1: 查准率和查全率均值","cell_type":"markdown","metadata":{"_id":"E04C546B2F68410EA9D9F1A708A1B38B","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"D84ED86CF36A4DB7B5C190DE4E117D93","trusted":true,"mdEditEnable":false},"unchanged":true},{"metadata":{"_id":"F6C232E6AD9A441DAF75BB314D17D1FE","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"0B2CFC6610EE48388273F0A8683A42A0","trusted":true},"cell_type":"code","outputs":[],"source":"#导入数据集\nfrom sklearn import datasets\niris = datasets.load_iris()\n# 应用svm算法\nfrom sklearn import svm\nclf = svm.SVC(kernel='linear', C=1)\n#交叉验证评估\nfrom sklearn.model_selection import cross_val_score\n# 进行5折交叉验证\nscores = cross_val_score(clf, iris.data, iris.target, cv=5)\nscores","execution_count":1,"unchanged":true},{"metadata":{"_id":"16D1FCD3C0F44CF692D6B1B41E01DF6D","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"196B05DD5E2F4701B157ABBBE9506526","trusted":true},"cell_type":"markdown","source":"# 3. 交叉验证划分数据集\n## k折交叉验证","unchanged":true},{"metadata":{"_id":"348D9C99572449908845208870CD7976","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"2B2F45F8F05A4AFF8C0FB2B59BD464CD","trusted":true},"cell_type":"code","outputs":[],"source":"from sklearn.model_selection import KFold\nimport numpy as np\n\nX = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\ny = np.array([1, 2, 3, 4])\n\n# 使用这里的n_splits设置k值\nkf = KFold(n_splits=2)\n\n# 得到训练集特征X[train_index]（二维集合）,结果y[train_index]（集合）\n# 得到测试集特征X[test_index]（二维集合）,结果y[test_index]（集合）\nfor train_index, test_index in kf.split(X):\n    print(\"train_index\", train_index, \"test_index\",test_index)\n    train_X, train_y = X[train_index], y[train_index]\n    test_X, test_y = X[test_index], y[test_index]","execution_count":8,"unchanged":true},{"metadata":{"_id":"E5CB7BB14C9140F086C9FCF7E4E195CF","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"DF7E7E0B4DF1467188F5D989FE4D8E0C","trusted":true},"cell_type":"markdown","source":"## p次k折交叉验证","unchanged":true},{"metadata":{"_id":"40D1BC81293140BBAFB3AC20170E24C3","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"FB30480C6F0A4AF6B6717D699A1630CC","trusted":true},"cell_type":"code","outputs":[],"source":"from sklearn.model_selection import RepeatedKFold\nimport numpy as np\nX = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\ny = np.array([1, 2, 3, 4])\n# 使用这里的n_splits设置k值，n_repeats设置重复次数\nkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=0)\nfor train_index, test_index in kf.split(X):\n    print('train_index', train_index, 'test_index', test_index)","execution_count":9,"unchanged":true},{"metadata":{"_id":"7F69400313A149E593960E4636836CA1","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"4512990D99CA497498244CBB7209E6ED","trusted":true},"cell_type":"markdown","source":"## 留一法","unchanged":true},{"metadata":{"_id":"C0C80E699E22445582BA339C84628C99","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"1838EE77DD9E459193CDEBFC72D933BB","trusted":true},"cell_type":"code","outputs":[],"source":"from sklearn.model_selection import LeaveOneOut\nX = [1, 2, 3, 4]\nloo = LeaveOneOut()\nfor train_index, test_index in loo.split(X):\n    print('train_index', train_index, 'test_index', test_index)","execution_count":10,"unchanged":true},{"metadata":{"_id":"EBAA48B8BAE94CCA92A3A6671553B67C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"2658962406DB48428EEE9A8808BBAA98","trusted":true},"cell_type":"markdown","source":"注：用LeavePOut(p=n) 代替LeaveOneOut() 可以留p个值\n# 参考资料：\n\n《机器学习》周志华\n[https://blog.csdn.net/qq_32590631/article/details/82831613](https://blog.csdn.net/qq_32590631/article/details/82831613)\n# 作业\n应用10折交叉验证，对给出的模型进行评估，得出模型评分","originalIndex":8,"newIndex":8,"unchanged":false,"patch":true,"sourceNew":["注：用LeavePOut(p=n) 代替LeaveOneOut() 可以留p个值\n","## 参考资料：\n","\n","《机器学习》周志华\n","[https://blog.csdn.net/qq_32590631/article/details/82831613](https://blog.csdn.net/qq_32590631/article/details/82831613)\n","# 作业\n","应用10折交叉验证，对给出的模型进行评估，得出模型评分"]},{"metadata":{"_id":"D29C442B960641DE8745D18EA56D9D22","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"153CF333AA4C4B1FB2BF28C20855D3DE","trusted":true},"cell_type":"code","outputs":[],"source":"# 导入数据集\nfrom sklearn import datasets, ensemble\ndata = datasets.load_breast_cancer()\n# 应用随机森林算法\nmodel = ensemble.RandomForestClassifier(n_estimators=30, max_depth=10)\n# 交叉验证评估","execution_count":null,"unchanged":true}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}